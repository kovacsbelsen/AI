{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Clasification: MNIST</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T11:04:54.219785Z",
     "start_time": "2021-02-25T11:04:29.358795Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T11:08:03.008758Z",
     "start_time": "2021-02-25T11:08:01.109235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (0.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: torch==1.7.1 in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (from torchvision) (1.7.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (from torch==1.7.1->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kovac\\anaconda3\\envs\\ml_tensorflow\\lib\\site-packages (from torchvision) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T11:07:12.510860Z",
     "start_time": "2021-02-25T11:07:11.784698Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxliary plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc72c974ed1d4d97abc2e3c02308c20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd2fce5e42b4fc2bea6d7bbc8ecce32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aec0010bb7482bbefeec6d2bc6357d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9004584a01254e188203690c5f2a9c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kovac\\anaconda3\\envs\\ML_tensorflow\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size   = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "          ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0148, -0.0078,  0.0153,  ...,  0.0317, -0.0332,  0.0128],\n",
      "        [ 0.0248,  0.0245, -0.0168,  ..., -0.0282,  0.0252, -0.0281],\n",
      "        [-0.0142,  0.0215,  0.0249,  ...,  0.0156, -0.0064,  0.0324],\n",
      "        ...,\n",
      "        [-0.0258,  0.0088, -0.0027,  ...,  0.0231, -0.0351,  0.0058],\n",
      "        [-0.0083,  0.0058,  0.0170,  ...,  0.0208, -0.0160, -0.0271],\n",
      "        [ 0.0260, -0.0056, -0.0118,  ...,  0.0135, -0.0146, -0.0009]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0335,  0.0353,  0.0270,  0.0012,  0.0123, -0.0013,  0.0187, -0.0008,\n",
      "        -0.0052,  0.0041, -0.0035, -0.0352, -0.0165,  0.0348,  0.0262,  0.0200,\n",
      "        -0.0170,  0.0340,  0.0169, -0.0267,  0.0182, -0.0007, -0.0299,  0.0305,\n",
      "        -0.0104, -0.0167,  0.0070, -0.0074, -0.0317, -0.0106, -0.0213, -0.0218,\n",
      "         0.0311, -0.0222,  0.0052,  0.0036,  0.0251,  0.0088, -0.0234, -0.0315,\n",
      "         0.0274,  0.0303, -0.0132, -0.0348,  0.0029,  0.0205, -0.0032, -0.0236,\n",
      "         0.0300, -0.0183,  0.0042, -0.0329,  0.0124, -0.0139,  0.0143,  0.0124,\n",
      "         0.0220,  0.0356, -0.0309,  0.0015, -0.0314, -0.0069, -0.0061,  0.0056,\n",
      "        -0.0060,  0.0252,  0.0194, -0.0170,  0.0331,  0.0157, -0.0029,  0.0115,\n",
      "        -0.0174, -0.0313, -0.0245, -0.0122, -0.0203,  0.0201, -0.0281,  0.0307,\n",
      "        -0.0289,  0.0203,  0.0037,  0.0170,  0.0166, -0.0119,  0.0346,  0.0064,\n",
      "         0.0210,  0.0222,  0.0245, -0.0127, -0.0221,  0.0032, -0.0205, -0.0144,\n",
      "         0.0320,  0.0094, -0.0317,  0.0320, -0.0102,  0.0158,  0.0099, -0.0100,\n",
      "         0.0131, -0.0277, -0.0185,  0.0258,  0.0145,  0.0337,  0.0306,  0.0352,\n",
      "         0.0077,  0.0055,  0.0191, -0.0099, -0.0159,  0.0185, -0.0328, -0.0053,\n",
      "         0.0085,  0.0034, -0.0082, -0.0058,  0.0048,  0.0348,  0.0018, -0.0169],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6275e-04,  2.9398e-03, -5.8476e-04,  ..., -3.8866e-03,\n",
       "          1.2438e-03, -1.3611e-03],\n",
       "        [-2.6389e-03,  1.7455e-02, -1.0590e-03,  ..., -6.8236e-03,\n",
       "          9.9953e-03,  2.1648e-02],\n",
       "        [-1.0831e-02,  2.6668e-02,  1.1027e-02,  ..., -2.3688e-03,\n",
       "         -3.1697e-03,  4.5791e-03],\n",
       "        ...,\n",
       "        [ 2.7673e-03, -5.6481e-03, -1.2405e-02,  ...,  1.0705e-03,\n",
       "          1.4904e-02,  2.8361e-02],\n",
       "        [-6.4448e-03,  5.1568e-03, -4.5589e-03,  ..., -1.1581e-02,\n",
       "          1.0635e-03, -7.9892e-05],\n",
       "        [ 9.0176e-04, -2.7348e-02, -2.1492e-02,  ..., -6.5940e-03,\n",
       "         -2.8571e-03,  1.2914e-03]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
    "\n",
    "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
    "\n",
    "$$\n",
    "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
    "\n",
    "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
    "\n",
    "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
    "\n",
    "<img src='assets/w1_backprop_graph.png' width=400px>\n",
    "\n",
    "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
    "$$\n",
    "\n",
    "We update our weights using this gradient with some learning rate $\\alpha$. \n",
    "\n",
    "$$\n",
    "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
    "$$\n",
    "\n",
    "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5838,  1.1479],\n",
      "        [ 0.6979, -0.3721]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3408, 1.3177],\n",
      "        [0.4871, 0.1384]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000001B8E1B1B430>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5710, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2919,  0.5739],\n",
      "        [ 0.3490, -0.1860]])\n",
      "tensor([[-0.2919,  0.5739],\n",
      "        [ 0.3490, -0.1860]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size  = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 2.9084e-02,  1.8363e-02,  2.8784e-02,  ..., -3.1330e-02,\n",
      "          9.3185e-03,  2.0464e-02],\n",
      "        [-1.9945e-03,  1.9823e-02, -1.8608e-02,  ...,  3.0007e-02,\n",
      "          2.2945e-02, -2.3598e-04],\n",
      "        [-3.1409e-02, -2.9947e-02, -1.9345e-02,  ...,  9.2402e-03,\n",
      "         -3.3556e-02,  2.3346e-05],\n",
      "        ...,\n",
      "        [-2.2001e-02, -1.2827e-02,  1.4273e-02,  ...,  5.1373e-03,\n",
      "          3.2451e-02,  3.1318e-02],\n",
      "        [ 3.2242e-02,  9.9277e-03, -8.3516e-04,  ...,  1.4982e-02,\n",
      "         -2.0092e-02,  2.4140e-02],\n",
      "        [ 1.3667e-02,  2.7407e-02, -2.5724e-02,  ...,  1.6883e-02,\n",
      "          3.2473e-02, -2.0877e-02]], requires_grad=True)\n",
      "Gradient - tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        [-0.0033, -0.0033, -0.0033,  ..., -0.0033, -0.0033, -0.0033]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model.fc1.weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 2.9087e-02,  1.8365e-02,  2.8786e-02,  ..., -3.1327e-02,\n",
      "          9.3209e-03,  2.0467e-02],\n",
      "        [-1.9960e-03,  1.9822e-02, -1.8610e-02,  ...,  3.0005e-02,\n",
      "          2.2943e-02, -2.3755e-04],\n",
      "        [-3.1384e-02, -2.9922e-02, -1.9320e-02,  ...,  9.2657e-03,\n",
      "         -3.3530e-02,  4.8912e-05],\n",
      "        ...,\n",
      "        [-2.2006e-02, -1.2832e-02,  1.4267e-02,  ...,  5.1319e-03,\n",
      "          3.2446e-02,  3.1313e-02],\n",
      "        [ 3.2248e-02,  9.9338e-03, -8.2900e-04,  ...,  1.4988e-02,\n",
      "         -2.0086e-02,  2.4146e-02],\n",
      "        [ 1.3700e-02,  2.7441e-02, -2.5690e-02,  ...,  1.6916e-02,\n",
      "          3.2506e-02, -2.0843e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0581\n",
      "\tIteration: 40\t Loss: 2.3022\n",
      "\tIteration: 80\t Loss: 2.2830\n",
      "\tIteration: 120\t Loss: 2.2601\n",
      "\tIteration: 160\t Loss: 2.2402\n",
      "\tIteration: 200\t Loss: 2.2193\n",
      "\tIteration: 240\t Loss: 2.1972\n",
      "\tIteration: 280\t Loss: 2.1734\n",
      "\tIteration: 320\t Loss: 2.1485\n",
      "\tIteration: 360\t Loss: 2.1157\n",
      "\tIteration: 400\t Loss: 2.0864\n",
      "\tIteration: 440\t Loss: 2.0430\n",
      "\tIteration: 480\t Loss: 2.0037\n",
      "\tIteration: 520\t Loss: 1.9569\n",
      "\tIteration: 560\t Loss: 1.9180\n",
      "\tIteration: 600\t Loss: 1.8716\n",
      "\tIteration: 640\t Loss: 1.8068\n",
      "\tIteration: 680\t Loss: 1.7592\n",
      "\tIteration: 720\t Loss: 1.6842\n",
      "\tIteration: 760\t Loss: 1.6198\n",
      "\tIteration: 800\t Loss: 1.5663\n",
      "\tIteration: 840\t Loss: 1.5217\n",
      "\tIteration: 880\t Loss: 1.4488\n",
      "\tIteration: 920\t Loss: 1.3841\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0346\n",
      "\tIteration: 40\t Loss: 1.2906\n",
      "\tIteration: 80\t Loss: 1.2598\n",
      "\tIteration: 120\t Loss: 1.1882\n",
      "\tIteration: 160\t Loss: 1.1578\n",
      "\tIteration: 200\t Loss: 1.1072\n",
      "\tIteration: 240\t Loss: 1.0661\n",
      "\tIteration: 280\t Loss: 1.0215\n",
      "\tIteration: 320\t Loss: 0.9712\n",
      "\tIteration: 360\t Loss: 0.9538\n",
      "\tIteration: 400\t Loss: 0.9203\n",
      "\tIteration: 440\t Loss: 0.8724\n",
      "\tIteration: 480\t Loss: 0.8934\n",
      "\tIteration: 520\t Loss: 0.8690\n",
      "\tIteration: 560\t Loss: 0.8128\n",
      "\tIteration: 600\t Loss: 0.7590\n",
      "\tIteration: 640\t Loss: 0.7666\n",
      "\tIteration: 680\t Loss: 0.7380\n",
      "\tIteration: 720\t Loss: 0.7251\n",
      "\tIteration: 760\t Loss: 0.7141\n",
      "\tIteration: 800\t Loss: 0.7226\n",
      "\tIteration: 840\t Loss: 0.6796\n",
      "\tIteration: 880\t Loss: 0.6694\n",
      "\tIteration: 920\t Loss: 0.6628\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0169\n",
      "\tIteration: 40\t Loss: 0.6199\n",
      "\tIteration: 80\t Loss: 0.6208\n",
      "\tIteration: 120\t Loss: 0.6138\n",
      "\tIteration: 160\t Loss: 0.6086\n",
      "\tIteration: 200\t Loss: 0.6024\n",
      "\tIteration: 240\t Loss: 0.5870\n",
      "\tIteration: 280\t Loss: 0.5742\n",
      "\tIteration: 320\t Loss: 0.5814\n",
      "\tIteration: 360\t Loss: 0.5474\n",
      "\tIteration: 400\t Loss: 0.5708\n",
      "\tIteration: 440\t Loss: 0.5493\n",
      "\tIteration: 480\t Loss: 0.5491\n",
      "\tIteration: 520\t Loss: 0.5486\n",
      "\tIteration: 560\t Loss: 0.5196\n",
      "\tIteration: 600\t Loss: 0.5416\n",
      "\tIteration: 640\t Loss: 0.5068\n",
      "\tIteration: 680\t Loss: 0.4644\n",
      "\tIteration: 720\t Loss: 0.4993\n",
      "\tIteration: 760\t Loss: 0.4844\n",
      "\tIteration: 800\t Loss: 0.4830\n",
      "\tIteration: 840\t Loss: 0.5114\n",
      "\tIteration: 880\t Loss: 0.4842\n",
      "\tIteration: 920\t Loss: 0.4632\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">MNIST Clasification: Exercise</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
    "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 400 units in the first hidden layer, 200 units in the second layer, and 100 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Your network here\n",
    "## TODO: Your network here\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc2 = nn.Linear(400, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, 10)\n",
    "\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
    "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
    "</a></p>\n",
    "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0541\n",
      "\tIteration: 40\t Loss: 2.1223\n",
      "\tIteration: 80\t Loss: 2.0926\n",
      "\tIteration: 120\t Loss: 2.0400\n",
      "\tIteration: 160\t Loss: 1.9997\n",
      "\tIteration: 200\t Loss: 1.9392\n",
      "\tIteration: 240\t Loss: 1.9291\n",
      "\tIteration: 280\t Loss: 1.8954\n",
      "\tIteration: 320\t Loss: 1.8799\n",
      "\tIteration: 360\t Loss: 1.8671\n",
      "\tIteration: 400\t Loss: 1.8586\n",
      "\tIteration: 440\t Loss: 1.8485\n",
      "\tIteration: 480\t Loss: 1.8382\n",
      "\tIteration: 520\t Loss: 1.8210\n",
      "\tIteration: 560\t Loss: 1.8276\n",
      "\tIteration: 600\t Loss: 1.8115\n",
      "\tIteration: 640\t Loss: 1.7975\n",
      "\tIteration: 680\t Loss: 1.7948\n",
      "\tIteration: 720\t Loss: 1.7812\n",
      "\tIteration: 760\t Loss: 1.7497\n",
      "\tIteration: 800\t Loss: 1.7572\n",
      "\tIteration: 840\t Loss: 1.7270\n",
      "\tIteration: 880\t Loss: 1.7359\n",
      "\tIteration: 920\t Loss: 1.7342\n",
      "75.0\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0433\n",
      "\tIteration: 40\t Loss: 1.7146\n",
      "\tIteration: 80\t Loss: 1.6985\n",
      "\tIteration: 120\t Loss: 1.6918\n",
      "\tIteration: 160\t Loss: 1.6769\n",
      "\tIteration: 200\t Loss: 1.6916\n",
      "\tIteration: 240\t Loss: 1.6896\n",
      "\tIteration: 280\t Loss: 1.6662\n",
      "\tIteration: 320\t Loss: 1.6717\n",
      "\tIteration: 360\t Loss: 1.6673\n",
      "\tIteration: 400\t Loss: 1.6540\n",
      "\tIteration: 440\t Loss: 1.6565\n",
      "\tIteration: 480\t Loss: 1.6596\n",
      "\tIteration: 520\t Loss: 1.6535\n",
      "\tIteration: 560\t Loss: 1.6378\n",
      "\tIteration: 600\t Loss: 1.6376\n",
      "\tIteration: 640\t Loss: 1.6586\n",
      "\tIteration: 680\t Loss: 1.6479\n",
      "\tIteration: 720\t Loss: 1.6501\n",
      "\tIteration: 760\t Loss: 1.6441\n",
      "\tIteration: 800\t Loss: 1.6407\n",
      "\tIteration: 840\t Loss: 1.6361\n",
      "\tIteration: 880\t Loss: 1.6651\n",
      "\tIteration: 920\t Loss: 1.6425\n",
      "85.9375\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0400\n",
      "\tIteration: 40\t Loss: 1.6378\n",
      "\tIteration: 80\t Loss: 1.6262\n",
      "\tIteration: 120\t Loss: 1.6405\n",
      "\tIteration: 160\t Loss: 1.6520\n",
      "\tIteration: 200\t Loss: 1.6379\n",
      "\tIteration: 240\t Loss: 1.6333\n",
      "\tIteration: 280\t Loss: 1.6387\n",
      "\tIteration: 320\t Loss: 1.6418\n",
      "\tIteration: 360\t Loss: 1.6305\n",
      "\tIteration: 400\t Loss: 1.6230\n",
      "\tIteration: 440\t Loss: 1.6254\n",
      "\tIteration: 480\t Loss: 1.6276\n",
      "\tIteration: 520\t Loss: 1.6298\n",
      "\tIteration: 560\t Loss: 1.6210\n",
      "\tIteration: 600\t Loss: 1.6404\n",
      "\tIteration: 640\t Loss: 1.6237\n",
      "\tIteration: 680\t Loss: 1.6320\n",
      "\tIteration: 720\t Loss: 1.6377\n",
      "\tIteration: 760\t Loss: 1.6271\n",
      "\tIteration: 800\t Loss: 1.6193\n",
      "\tIteration: 840\t Loss: 1.6334\n",
      "\tIteration: 880\t Loss: 1.6209\n",
      "\tIteration: 920\t Loss: 1.6226\n",
      "86.45833333333333\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "\n",
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            output = model.forward(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print((100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your network here\n",
    "## TODO: Your network here\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc2 = nn.Linear(400, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, 10)\n",
    "\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0384\n",
      "\tIteration: 40\t Loss: 1.5288\n",
      "\tIteration: 80\t Loss: 1.5288\n",
      "\tIteration: 120\t Loss: 1.5322\n",
      "\tIteration: 160\t Loss: 1.5333\n",
      "\tIteration: 200\t Loss: 1.5303\n",
      "\tIteration: 240\t Loss: 1.5312\n",
      "\tIteration: 280\t Loss: 1.5402\n",
      "\tIteration: 320\t Loss: 1.5350\n",
      "\tIteration: 360\t Loss: 1.5318\n",
      "\tIteration: 400\t Loss: 1.5293\n",
      "\tIteration: 440\t Loss: 1.5318\n",
      "\tIteration: 480\t Loss: 1.5306\n",
      "\tIteration: 520\t Loss: 1.5276\n",
      "\tIteration: 560\t Loss: 1.5330\n",
      "\tIteration: 600\t Loss: 1.5236\n",
      "\tIteration: 640\t Loss: 1.5327\n",
      "\tIteration: 680\t Loss: 1.5188\n",
      "\tIteration: 720\t Loss: 1.5312\n",
      "\tIteration: 760\t Loss: 1.5301\n",
      "\tIteration: 800\t Loss: 1.5318\n",
      "\tIteration: 840\t Loss: 1.5280\n",
      "\tIteration: 880\t Loss: 1.5215\n",
      "\tIteration: 920\t Loss: 1.5253\n",
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (32) to match target batch_size (64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-e6fe8f8534d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_tensorflow\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_tensorflow\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_tensorflow\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2261\u001b[1;33m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0m\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (64)."
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "\n",
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter(testloader):\n",
    "            print(images.shape, labels.shape)\n",
    "            loss = criterion(output, labels)\n",
    "            output = model.forward(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print((100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
